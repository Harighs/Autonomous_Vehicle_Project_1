{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not determine the notebook's path: name 'notebook_path' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Attempt to get the current Jupyter notebook's path\n",
    "import IPython\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    FILE = Path(IPython.get_ipython().starting_dir)\n",
    "    print(f\"Current notebook path: {notebook_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not determine the notebook's path: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "try:\n",
    "    import comet_ml  # must be imported before torch (if installed)\n",
    "except ImportError:\n",
    "    comet_ml = None\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "ROOT = FILE.parents[0]  # YOLOv3 root directory\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
    "\n",
    "import val as validate  # for end-of-epoch mAP\n",
    "from models.experimental import attempt_load\n",
    "from models.yolo import Model\n",
    "from utils.autoanchor import check_anchors\n",
    "from utils.autobatch import check_train_batch_size\n",
    "from utils.callbacks import Callbacks\n",
    "from utils.dataloaders import create_dataloader\n",
    "from utils.downloads import attempt_download, is_url\n",
    "from utils.general import (\n",
    "    LOGGER,\n",
    "    TQDM_BAR_FORMAT,\n",
    "    check_amp,\n",
    "    check_dataset,\n",
    "    check_file,\n",
    "    check_git_info,\n",
    "    check_git_status,\n",
    "    check_img_size,\n",
    "    check_requirements,\n",
    "    check_suffix,\n",
    "    check_yaml,\n",
    "    colorstr,\n",
    "    get_latest_run,\n",
    "    increment_path,\n",
    "    init_seeds,\n",
    "    intersect_dicts,\n",
    "    labels_to_class_weights,\n",
    "    labels_to_image_weights,\n",
    "    methods,\n",
    "    one_cycle,\n",
    "    print_args,\n",
    "    print_mutation,\n",
    "    strip_optimizer,\n",
    "    yaml_save,\n",
    ")\n",
    "from utils.loggers import Loggers\n",
    "from utils.loggers.comet.comet_utils import check_comet_resume\n",
    "from utils.loss import ComputeLoss\n",
    "from utils.metrics import fitness\n",
    "from utils.plots import plot_evolve\n",
    "from utils.torch_utils import (\n",
    "    EarlyStopping,\n",
    "    ModelEMA,\n",
    "    de_parallel,\n",
    "    select_device,\n",
    "    smart_DDP,\n",
    "    smart_optimizer,\n",
    "    smart_resume,\n",
    "    torch_distributed_zero_first,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RANK and other necessary globals\n",
    "RANK = -1  # Example definition, adjust based on your specific use case\n",
    "ROOT = Path.cwd()  # Example definition, assuming ROOT is the current working directory\n",
    "LOCAL_RANK = -1  # Example definition, adjust based on your specific use case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/hari/Projects/autonomous_vechicle_project_1/new_dir')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE / 'new_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "\n",
    "# weights = FILE / 'runs/train/exp/weights/best.pt'\n",
    "# cfg = FILE / 'models/yolov3.yaml'\n",
    "# data = FILE / 'data/coco128.yaml'\n",
    "# imgsz = 640\n",
    "# batch_size = 16\n",
    "# hyp = FILE / 'data/hyps/hyp.scratch.yaml'\n",
    "# opt = 'SGD'\n",
    "# device = \"\"\n",
    "# callback = Callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(opt, callbacks=Callbacks()):\n",
    "    # Checks\n",
    "    if RANK in {-1, 0}:\n",
    "        print_args(vars(opt))\n",
    "        check_git_status()\n",
    "        check_requirements(ROOT / \"requirements.txt\")\n",
    "\n",
    "    # Resume (from specified or most recent last.pt)\n",
    "    if opt.resume and not check_comet_resume(opt) and not opt.evolve:\n",
    "        last = Path(check_file(opt.resume) if isinstance(opt.resume, str) else get_latest_run())\n",
    "        opt_yaml = last.parent.parent / \"opt.yaml\"  # train options yaml\n",
    "        opt_data = opt.data  # original dataset\n",
    "        if opt_yaml.is_file():\n",
    "            with open(opt_yaml, errors=\"ignore\") as f:\n",
    "                d = yaml.safe_load(f)\n",
    "        else:\n",
    "            d = torch.load(last, map_location=\"cpu\")[\"opt\"]\n",
    "        opt = argparse.Namespace(**d)  # replace\n",
    "        opt.cfg, opt.weights, opt.resume = \"\", str(last), True  # reinstate\n",
    "        if is_url(opt_data):\n",
    "            opt.data = check_file(opt_data)  # avoid HUB resume auth timeout\n",
    "    else:\n",
    "        opt.data, opt.cfg, opt.hyp, opt.weights, opt.project = (\n",
    "            check_file(opt.data),\n",
    "            check_yaml(opt.cfg),\n",
    "            check_yaml(opt.hyp),\n",
    "            str(opt.weights),\n",
    "            str(opt.project),\n",
    "        )  # checks\n",
    "        assert len(opt.cfg) or len(opt.weights), \"either --cfg or --weights must be specified\"\n",
    "        if opt.evolve:\n",
    "            if opt.project == str(ROOT / \"runs/train\"):  # if default project name, rename to runs/evolve\n",
    "                opt.project = str(ROOT / \"runs/evolve\")\n",
    "            opt.exist_ok, opt.resume = opt.resume, False  # pass resume to exist_ok and disable resume\n",
    "        if opt.name == \"cfg\":\n",
    "            opt.name = Path(opt.cfg).stem  # use model.yaml as name\n",
    "        opt.save_dir = str(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))\n",
    "\n",
    "    # DDP mode\n",
    "    device = select_device(opt.device, batch_size=opt.batch_size)\n",
    "    if LOCAL_RANK != -1:\n",
    "        msg = \"is not compatible with YOLOv3 Multi-GPU DDP training\"\n",
    "        assert not opt.image_weights, f\"--image-weights {msg}\"\n",
    "        assert not opt.evolve, f\"--evolve {msg}\"\n",
    "        assert opt.batch_size != -1, f\"AutoBatch with --batch-size -1 {msg}, please pass a valid --batch-size\"\n",
    "        assert opt.batch_size % WORLD_SIZE == 0, f\"--batch-size {opt.batch_size} must be multiple of WORLD_SIZE\"\n",
    "        assert torch.cuda.device_count() > LOCAL_RANK, \"insufficient CUDA devices for DDP command\"\n",
    "        torch.cuda.set_device(LOCAL_RANK)\n",
    "        device = torch.device(\"cuda\", LOCAL_RANK)\n",
    "        dist.init_process_group(backend=\"nccl\" if dist.is_nccl_available() else \"gloo\")\n",
    "\n",
    "    # Train\n",
    "    if not opt.evolve:\n",
    "        train(opt.hyp, opt, device, callbacks)\n",
    "\n",
    "    # Evolve hyperparameters (optional)\n",
    "    else:\n",
    "        # Hyperparameter evolution metadata (mutation scale 0-1, lower_limit, upper_limit)\n",
    "        meta = {\n",
    "            \"lr0\": (1, 1e-5, 1e-1),  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
    "            \"lrf\": (1, 0.01, 1.0),  # final OneCycleLR learning rate (lr0 * lrf)\n",
    "            \"momentum\": (0.3, 0.6, 0.98),  # SGD momentum/Adam beta1\n",
    "            \"weight_decay\": (1, 0.0, 0.001),  # optimizer weight decay\n",
    "            \"warmup_epochs\": (1, 0.0, 5.0),  # warmup epochs (fractions ok)\n",
    "            \"warmup_momentum\": (1, 0.0, 0.95),  # warmup initial momentum\n",
    "            \"warmup_bias_lr\": (1, 0.0, 0.2),  # warmup initial bias lr\n",
    "            \"box\": (1, 0.02, 0.2),  # box loss gain\n",
    "            \"cls\": (1, 0.2, 4.0),  # cls loss gain\n",
    "            \"cls_pw\": (1, 0.5, 2.0),  # cls BCELoss positive_weight\n",
    "            \"obj\": (1, 0.2, 4.0),  # obj loss gain (scale with pixels)\n",
    "            \"obj_pw\": (1, 0.5, 2.0),  # obj BCELoss positive_weight\n",
    "            \"iou_t\": (0, 0.1, 0.7),  # IoU training threshold\n",
    "            \"anchor_t\": (1, 2.0, 8.0),  # anchor-multiple threshold\n",
    "            \"anchors\": (2, 2.0, 10.0),  # anchors per output grid (0 to ignore)\n",
    "            \"fl_gamma\": (0, 0.0, 2.0),  # focal loss gamma (efficientDet default gamma=1.5)\n",
    "            \"hsv_h\": (1, 0.0, 0.1),  # image HSV-Hue augmentation (fraction)\n",
    "            \"hsv_s\": (1, 0.0, 0.9),  # image HSV-Saturation augmentation (fraction)\n",
    "            \"hsv_v\": (1, 0.0, 0.9),  # image HSV-Value augmentation (fraction)\n",
    "            \"degrees\": (1, 0.0, 45.0),  # image rotation (+/- deg)\n",
    "            \"translate\": (1, 0.0, 0.9),  # image translation (+/- fraction)\n",
    "            \"scale\": (1, 0.0, 0.9),  # image scale (+/- gain)\n",
    "            \"shear\": (1, 0.0, 10.0),  # image shear (+/- deg)\n",
    "            \"perspective\": (0, 0.0, 0.001),  # image perspective (+/- fraction), range 0-0.001\n",
    "            \"flipud\": (1, 0.0, 1.0),  # image flip up-down (probability)\n",
    "            \"fliplr\": (0, 0.0, 1.0),  # image flip left-right (probability)\n",
    "            \"mosaic\": (1, 0.0, 1.0),  # image mixup (probability)\n",
    "            \"mixup\": (1, 0.0, 1.0),  # image mixup (probability)\n",
    "            \"copy_paste\": (1, 0.0, 1.0),\n",
    "        }  # segment copy-paste (probability)\n",
    "\n",
    "        with open(opt.hyp, errors=\"ignore\") as f:\n",
    "            hyp = yaml.safe_load(f)  # load hyps dict\n",
    "            if \"anchors\" not in hyp:  # anchors commented in hyp.yaml\n",
    "                hyp[\"anchors\"] = 3\n",
    "        if opt.noautoanchor:\n",
    "            del hyp[\"anchors\"], meta[\"anchors\"]\n",
    "        opt.noval, opt.nosave, save_dir = True, True, Path(opt.save_dir)  # only val/save final epoch\n",
    "        # ei = [isinstance(x, (int, float)) for x in hyp.values()]  # evolvable indices\n",
    "        evolve_yaml, evolve_csv = save_dir / \"hyp_evolve.yaml\", save_dir / \"evolve.csv\"\n",
    "        if opt.bucket:\n",
    "            # download evolve.csv if exists\n",
    "            subprocess.run(\n",
    "                [\n",
    "                    \"gsutil\",\n",
    "                    \"cp\",\n",
    "                    f\"gs://{opt.bucket}/evolve.csv\",\n",
    "                    str(evolve_csv),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        for _ in range(opt.evolve):  # generations to evolve\n",
    "            if evolve_csv.exists():  # if evolve.csv exists: select best hyps and mutate\n",
    "                # Select parent(s)\n",
    "                parent = \"single\"  # parent selection method: 'single' or 'weighted'\n",
    "                x = np.loadtxt(evolve_csv, ndmin=2, delimiter=\",\", skiprows=1)\n",
    "                n = min(5, len(x))  # number of previous results to consider\n",
    "                x = x[np.argsort(-fitness(x))][:n]  # top n mutations\n",
    "                w = fitness(x) - fitness(x).min() + 1e-6  # weights (sum > 0)\n",
    "                if parent == \"single\" or len(x) == 1:\n",
    "                    # x = x[random.randint(0, n - 1)]  # random selection\n",
    "                    x = x[random.choices(range(n), weights=w)[0]]  # weighted selection\n",
    "                elif parent == \"weighted\":\n",
    "                    x = (x * w.reshape(n, 1)).sum(0) / w.sum()  # weighted combination\n",
    "\n",
    "                # Mutate\n",
    "                mp, s = 0.8, 0.2  # mutation probability, sigma\n",
    "                npr = np.random\n",
    "                npr.seed(int(time.time()))\n",
    "                g = np.array([meta[k][0] for k in hyp.keys()])  # gains 0-1\n",
    "                ng = len(meta)\n",
    "                v = np.ones(ng)\n",
    "                while all(v == 1):  # mutate until a change occurs (prevent duplicates)\n",
    "                    v = (g * (npr.random(ng) < mp) * npr.randn(ng) * npr.random() * s + 1).clip(0.3, 3.0)\n",
    "                for i, k in enumerate(hyp.keys()):  # plt.hist(v.ravel(), 300)\n",
    "                    hyp[k] = float(x[i + 7] * v[i])  # mutate\n",
    "\n",
    "            # Constrain to limits\n",
    "            for k, v in meta.items():\n",
    "                hyp[k] = max(hyp[k], v[1])  # lower limit\n",
    "                hyp[k] = min(hyp[k], v[2])  # upper limit\n",
    "                hyp[k] = round(hyp[k], 5)  # significant digits\n",
    "\n",
    "            # Train mutation\n",
    "            results = train(hyp.copy(), opt, device, callbacks)\n",
    "            callbacks = Callbacks()\n",
    "            # Write mutation results\n",
    "            keys = (\n",
    "                \"metrics/precision\",\n",
    "                \"metrics/recall\",\n",
    "                \"metrics/mAP_0.5\",\n",
    "                \"metrics/mAP_0.5:0.95\",\n",
    "                \"val/box_loss\",\n",
    "                \"val/obj_loss\",\n",
    "                \"val/cls_loss\",\n",
    "            )\n",
    "            print_mutation(keys, results, hyp.copy(), save_dir, opt.bucket)\n",
    "\n",
    "        # Plot results\n",
    "        plot_evolve(evolve_csv)\n",
    "        LOGGER.info(\n",
    "            f'Hyperparameter evolution finished {opt.evolve} generations\\n'\n",
    "            f\"Results saved to {colorstr('bold', save_dir)}\\n\"\n",
    "            f'Usage example: $ python train.py --hyp {evolve_yaml}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': PosixPath('runs/train/with_albumentation2/weights/best.pt'), 'cfg': 'models/yolov5s.yaml', 'data': PosixPath('data/dataset/data.yaml'), 'hyp': PosixPath('data/hyps/hyp.scratch-low.yaml'), 'epochs': 500, 'batch_size': 32, 'imgsz': 640, 'rect': False, 'resume': False, 'nosave': False, 'noval': False, 'noautoanchor': False, 'noplots': False, 'evolve': 300, 'bucket': '', 'cache': 'ram', 'image_weights': False, 'device': '', 'multi_scale': False, 'single_cls': False, 'optimizer': 'SGD', 'sync_bn': False, 'workers': 8, 'project': PosixPath('runs/train'), 'name': 'notebook_test', 'exist_ok': False, 'quad': False, 'cos_lr': False, 'label_smoothing': 0.0, 'patience': 100, 'freeze': [0], 'save_period': -1, 'seed': 0, 'local_rank': -1, 'entity': None, 'upload_dataset': False, 'bbox_interval': -1, 'artifact_alias': 'latest'}\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Manually create an options object similar to what parse_opt would return\n",
    "opt = SimpleNamespace(\n",
    "    weights=Path(\"runs/train/with_albumentation2/weights/best.pt\"),\n",
    "    cfg=\"models/yolov5s.yaml\",\n",
    "    data=Path(\"data/dataset/data.yaml\"),\n",
    "    hyp=Path(\"data/hyps/hyp.scratch-low.yaml\"),\n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    imgsz=640,\n",
    "    rect=False,\n",
    "    resume=False,\n",
    "    nosave=False,\n",
    "    noval=False,\n",
    "    noautoanchor=False,\n",
    "    noplots=False,\n",
    "    evolve=300,  # or None to disable\n",
    "    bucket=\"\",\n",
    "    cache=\"ram\",  # or None to disable\n",
    "    image_weights=False,\n",
    "    device=\"\",\n",
    "    multi_scale=False,\n",
    "    single_cls=False,\n",
    "    optimizer=\"SGD\",\n",
    "    sync_bn=False,\n",
    "    workers=8,\n",
    "    project=Path(\"runs/train\"),\n",
    "    name=\"notebook_test\",\n",
    "    exist_ok=False,\n",
    "    quad=False,\n",
    "    cos_lr=False,\n",
    "    label_smoothing=0.0,\n",
    "    patience=100,\n",
    "    freeze=[0],  # List of layers to freeze, example: [10] or [0, 1, 2]\n",
    "    save_period=-1,\n",
    "    seed=0,\n",
    "    local_rank=-1,\n",
    "    entity=None,\n",
    "    upload_dataset=False,  # or True to enable\n",
    "    bbox_interval=-1,\n",
    "    artifact_alias=\"latest\"\n",
    ")\n",
    "\n",
    "# Now you can print or inspect opt to see your configurations\n",
    "print(vars(opt))\n",
    "\n",
    "# Assuming you have a function that takes these options\n",
    "# For example, let's call it main(opt)\n",
    "# main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    # Assuming 'opt' is defined in the global scope or a previous cell in Jupyter notebook\n",
    "    global opt\n",
    "    # Now 'opt' contains all the configurations set previously\n",
    "    \n",
    "    # Call main function or any other function that requires 'opt'\n",
    "    main(opt)\n",
    "    \n",
    "    # Optionally, return 'opt' if you want to inspect or use it after modifications\n",
    "    return opt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=data/dataset/data.yaml, weights=['runs/train/with_albumentation2/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.5, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv3 🚀 f5aed80d Python-3.9.18 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12036MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv3s summary: 157 layers, 7209703 parameters, 0 gradients, 16.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/hari/Projects/autonomous_vechicle_project_1/data/dataset/valid/labels.cache... 770 images, 3 backgrounds, 0 corrupt: 100%|██████████| 770/770 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 25/25 [00:06<00:00,  3.65it/s]\n",
      "                   all        770        866      0.842      0.789      0.849       0.55\n",
      "Speed: 0.2ms pre-process, 4.5ms inference, 0.9ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "Finally Accuracy: 0.860\n",
      " mAP: 0.5500217258779461\n",
      " Average Speed: 1.87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run val.py --data data/dataset/data.yaml --weights runs/train/with_albumentation2/weights/best.pt --batch-size 32 --imgsz 640 --task val\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
